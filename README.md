# Clasificaci√≥n de Galaxias con Estructura de Marea y sin Estructura de Marea

## üìã Descripci√≥n del Proyecto

Este proyecto utiliza **Redes Neuronales Convolucionales (CNN)** y **Transfer Learning** para clasificar galaxias en dos categor√≠as:
- **Galaxias con estructura de marea** (Tidal=1): Galaxias que presentan perturbaciones gravitacionales causadas por interacciones con otras galaxias
- **Galaxias sin estructura de marea** (Tidal=0): Galaxias sin evidencia de interacciones gravitacionales recientes

El proyecto fue desarrollado como trabajo final para el curso de **Introducci√≥n a Redes Neuronales** de la Facultad de Ciencias, UNAM (Semestre 2026-1).

## üë• Autores

- **Angel Galv√°n Magdiel Joshua** (319052590)
- **G√≥mez G√≥mez Patricio Emanuel** (319024234)

## üéØ Objetivos

1. Desarrollar un modelo de clasificaci√≥n binaria para identificar estructuras de marea en galaxias
2. Comparar el desempe√±o de una CNN personalizada vs. modelos preentrenados (ResNet50)
3. Implementar t√©cnicas para manejar el desbalance de clases en el dataset
4. Optimizar el modelo para reducir el sobreajuste (overfitting)

## üìä Dataset

El proyecto utiliza el archivo `galaxias.csv` que contiene:
- **name**: Identificador de la galaxia (formato manga-xxxx-xxxx)
- **Type**: Tipo morfol√≥gico de la galaxia
- **Bars**: Presencia de barras en la galaxia
- **Tidal**: Variable objetivo (0 = sin estructura de marea, 1 = con estructura de marea)
- **g-i**: √çndice de color (diferencia entre magnitudes g e i)

### Desbalance de Clases
El dataset presenta un **fuerte desbalance**: la clase 0 (sin estructura de marea) tiene aproximadamente **5 veces m√°s muestras** que la clase 1 (con estructura de marea). Esto requiere t√©cnicas especiales como:
- Pesos de clase (class weights) en la funci√≥n de p√©rdida
- Data augmentation para la clase minoritaria
- M√©tricas de evaluaci√≥n equilibradas (F1-Score, Recall, Precision)

## üèóÔ∏è Arquitecturas Implementadas

### 1. CNN Personalizada (Modelo Inicial)
- **3 bloques convolucionales** para extracci√≥n jer√°rquica de caracter√≠sticas
- **Batch Normalization** para estabilizar el entrenamiento
- **Dropout (0.6)** para mitigar el overfitting
- **Resultados**: Precisi√≥n global del 81%, pero con bajo desempe√±o en la clase minoritaria (F1=0.29)

### 2. ResNet50 con Transfer Learning
- Modelo preentrenado en **ImageNet** con m√°s de 1 mill√≥n de im√°genes
- **Bloques residuales** con conexiones de salto (skip connections)
- **Fine-tuning** de las √∫ltimas capas para adaptarse al problema espec√≠fico
- **Resultados**: Mejora significativa al 87.15% en validaci√≥n, con mejor identificaci√≥n de estructuras de marea (Recall del 50%)

### 3. Modelo Optimizado (ResNet50 Mejorado)
Incluye t√©cnicas avanzadas para reducir overfitting:
- Congelamiento selectivo de capas tempranas
- Clasificador m√°s profundo con dropout progresivo
- Learning rate con warmup y cosine decay
- Stochastic Weight Averaging (SWA)

## üîß Tecnolog√≠as y Librer√≠as

- **Python 3.x**
- **PyTorch**: Framework principal para deep learning
- **torchvision**: Para transformaciones de im√°genes y modelos preentrenados
- **NumPy**: C√°lculos num√©ricos
- **Pandas**: Manipulaci√≥n de datos
- **Matplotlib/Seaborn**: Visualizaci√≥n de datos
- **scikit-learn**: M√©tricas de evaluaci√≥n y preprocesamiento

## üöÄ Uso

1. **Instalar dependencias**:
```bash
pip install torch torchvision numpy pandas matplotlib seaborn scikit-learn
```

2. **Abrir el notebook**:
```bash
jupyter notebook "proyecto_finalRedes (1).ipynb"
```

3. **Ejecutar las celdas** en orden para:
   - Cargar y explorar los datos
   - Entrenar los modelos (CNN personalizada y ResNet50)
   - Evaluar el desempe√±o con m√©tricas detalladas
   - Visualizar resultados y matrices de confusi√≥n

## üìà Resultados Principales

| Modelo | Precisi√≥n Global | F1-Score (Clase 0) | F1-Score (Clase 1) | Recall (Clase 1) |
|--------|------------------|--------------------|--------------------|------------------|
| CNN Personalizada | 81% | 0.89 | 0.29 | ~15% |
| ResNet50 (Transfer Learning) | 87.15% | ~0.93 | ~0.52 | 50% |

### Hallazgos Clave
- **Transfer Learning es superior**: ResNet50 duplic√≥ la capacidad de identificaci√≥n de galaxias con estructura de marea
- **El desbalance afecta significativamente**: La clase minoritaria siempre tiene menor desempe√±o
- **Data augmentation es crucial**: Rotaciones, flips y ajustes de color mejoran la generalizaci√≥n
- **El sobreajuste es un desaf√≠o**: El modelo alcanza ~99% en entrenamiento vs ~86% en validaci√≥n

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ README.md                          # Este archivo
‚îú‚îÄ‚îÄ galaxias.csv                       # Dataset con informaci√≥n de galaxias
‚îî‚îÄ‚îÄ proyecto_finalRedes (1).ipynb     # Notebook principal con todo el c√≥digo
```

## üî¨ Metodolog√≠a

1. **Carga y exploraci√≥n de datos**: An√°lisis estad√≠stico y visualizaci√≥n del dataset
2. **Preprocesamiento**: Normalizaci√≥n, divisi√≥n train/val/test (70/15/15)
3. **Data Augmentation**: Rotaciones, flips, variaciones de brillo/contraste
4. **Entrenamiento con CNN personalizada**: Baseline inicial
5. **Transfer Learning con ResNet50**: Mejora significativa del desempe√±o
6. **Optimizaci√≥n y reducci√≥n de overfitting**: T√©cnicas avanzadas de regularizaci√≥n
7. **Evaluaci√≥n**: M√©tricas detalladas, matrices de confusi√≥n y an√°lisis de resultados

## üìù Conclusiones

- Las redes neuronales convolucionales pueden identificar efectivamente estructuras de marea en galaxias
- Transfer Learning con modelos preentrenados (ResNet50) supera significativamente a arquitecturas personalizadas
- El manejo adecuado del desbalance de clases es fundamental para obtener buenos resultados
- Se requieren t√©cnicas de regularizaci√≥n robustas para evitar el sobreajuste en datasets astron√≥micos

## üìö Referencias

- **ImageNet**: Base de datos utilizada para preentrenar ResNet50
- **MaNGA Survey**: Posible fuente de las im√°genes de galaxias (identificadores manga-xxxx-xxxx)
- **ResNet Paper**: He et al. (2016) - Deep Residual Learning for Image Recognition

## üéì Instituci√≥n

**Universidad Nacional Aut√≥noma de M√©xico (UNAM)**  
Facultad de Ciencias  
Curso: Introducci√≥n a Redes Neuronales  
Semestre: 2026-1